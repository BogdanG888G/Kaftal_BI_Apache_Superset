import requests
import logging
import time
import urllib.parse
from typing import Dict, Optional, Tuple, List
import re
import time
import logging
from typing import Dict, Any, List
import threading
import os
import pyodbc
import numpy as np
from tqdm import tqdm
from datetime import date
import hashlib

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –∫—ç—à–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π
_db_connections = {}
_db_lock = threading.Lock()

def get_db_connection():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
    global _db_connections, _db_lock
    
    thread_id = threading.get_ident()
    
    with _db_lock:
        if thread_id in _db_connections:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –µ—â–µ –∂–∏–≤–æ
                _db_connections[thread_id].cursor().execute("SELECT 1")
                return _db_connections[thread_id]
            except:
                # –ï—Å–ª–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Ä–∞–∑–æ—Ä–≤–∞–Ω–æ, —É–¥–∞–ª—è–µ–º –µ–≥–æ –∏–∑ –∫—ç—à–∞
                del _db_connections[thread_id]
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        server = os.environ.get('MSSQL_SERVER', 'host.docker.internal')
        database = os.environ.get('MSSQL_DATABASE', 'Stage')
        username = os.environ.get('MSSQL_USER', 'superset_user')
        password = os.environ.get('MSSQL_PASSWORD', '123')
        port = os.environ.get('MSSQL_PORT', '1433')
        
        conn_str = (
            f"DRIVER={{ODBC Driver 17 for SQL Server}};"
            f"SERVER={server},{port};"
            f"DATABASE={database};"
            f"UID={username};"
            f"PWD={password};"
            "Encrypt=yes;"
            "TrustServerCertificate=yes;"
            "Connection Timeout=30;"
        )
        
        logger.info(f"–°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ SQL Server: {server},{port}")
        conn = pyodbc.connect(conn_str)
        _db_connections[thread_id] = conn
        
        return conn
    
def generate_address_hash(address: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ö–µ—à–∞ –∞–¥—Ä–µ—Å–∞ –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏"""
    return hashlib.sha256(address.encode('utf-8')).hexdigest()

class YandexGeoProcessor:
    def __init__(self, api_keys: List[str] = None):
        self.api_keys = api_keys or []
        self.current_key_index = 0
        self.geocoder_url = "https://geocode-maps.yandex.ru/1.x/"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json'
        })
        
        # –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã—Ö –æ–∫—Ä—É–≥–æ–≤ –∏ —Å—É–±—ä–µ–∫—Ç–æ–≤
        self.federal_districts = {
            '–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥': ['–ú–æ—Å–∫–≤–∞', '–ú–æ—Å–∫–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–ë–µ–ª–≥–æ—Ä–æ–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–ë—Ä—è–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', 
                                              '–í–ª–∞–¥–∏–º–∏—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–í–æ—Ä–æ–Ω–µ–∂—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–ò–≤–∞–Ω–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', 
                                              '–ö–∞–ª—É–∂—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–ö–æ—Å—Ç—Ä–æ–º—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–ö—É—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–õ–∏–ø–µ—Ü–∫–∞—è –æ–±–ª–∞—Å—Ç—å',
                                              '–û—Ä–ª–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–†—è–∑–∞–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–°–º–æ–ª–µ–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–¢–∞–º–±–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å',
                                              '–¢–≤–µ—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–¢—É–ª—å—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–Ø—Ä–æ—Å–ª–∞–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å'],
            '–°–µ–≤–µ—Ä–æ-–ó–∞–ø–∞–¥–Ω—ã–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥': ['–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥', '–õ–µ–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–ê—Ä—Ö–∞–Ω–≥–µ–ª—å—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', 
                                                  '–í–æ–ª–æ–≥–æ–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–ö–∞–ª–∏–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ö–∞—Ä–µ–ª–∏—è',
                                                  '–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ö–æ–º–∏', '–ú—É—Ä–º–∞–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–ù–µ–Ω–µ—Ü–∫–∏–π –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –æ–∫—Ä—É–≥',
                                                  '–ù–æ–≤–≥–æ—Ä–æ–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–ü—Å–∫–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å'],
            '–Æ–∂–Ω—ã–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥': ['–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ê–¥—ã–≥–µ—è', '–ê—Å—Ç—Ä–∞—Ö–∞–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–í–æ–ª–≥–æ–≥—Ä–∞–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ö–∞–ª–º—ã–∫–∏—è',
                                        '–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä—Å–∫–∏–π –∫—Ä–∞–π', '–†–æ—Å—Ç–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ö—Ä—ã–º', '–°–µ–≤–∞—Å—Ç–æ–ø–æ–ª—å'],
            '–°–µ–≤–µ—Ä–æ-–ö–∞–≤–∫–∞–∑—Å–∫–∏–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥': ['–†–µ—Å–ø—É–±–ª–∏–∫–∞ –î–∞–≥–µ—Å—Ç–∞–Ω', '–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ò–Ω–≥—É—à–µ—Ç–∏—è', '–ö–∞–±–∞—Ä–¥–∏–Ω–æ-–ë–∞–ª–∫–∞—Ä—Å–∫–∞—è –†–µ—Å–ø—É–±–ª–∏–∫–∞',
                                                    '–ö–∞—Ä–∞—á–∞–µ–≤–æ-–ß–µ—Ä–∫–µ—Å—Å–∫–∞—è –†–µ—Å–ø—É–±–ª–∏–∫–∞', '–†–µ—Å–ø—É–±–ª–∏–∫–∞ –°–µ–≤–µ—Ä–Ω–∞—è –û—Å–µ—Ç–∏—è ‚Äî –ê–ª–∞–Ω–∏—è',
                                                    '–ß–µ—á–µ–Ω—Å–∫–∞—è –†–µ—Å–ø—É–±–ª–∏–∫–∞', '–°—Ç–∞–≤—Ä–æ–ø–æ–ª—å—Å–∫–∏–π –∫—Ä–∞–π'],
            '–ü—Ä–∏–≤–æ–ª–∂—Å–∫–∏–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥': ['–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ë–∞—à–∫–æ—Ä—Ç–æ—Å—Ç–∞–Ω', '–ö–∏—Ä–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ú–∞—Ä–∏–π –≠–ª', 
                                              '–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ú–æ—Ä–¥–æ–≤–∏—è', '–ù–∏–∂–µ–≥–æ—Ä–æ–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–û—Ä–µ–Ω–±—É—Ä–≥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', 
                                              '–ü–µ–Ω–∑–µ–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–ü–µ—Ä–º—Å–∫–∏–π –∫—Ä–∞–π', '–°–∞–º–∞—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–°–∞—Ä–∞—Ç–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å',
                                              '–†–µ—Å–ø—É–±–ª–∏–∫–∞ –¢–∞—Ç–∞—Ä—Å—Ç–∞–Ω', '–£–¥–º—É—Ä—Ç—Å–∫–∞—è –†–µ—Å–ø—É–±–ª–∏–∫–∞', '–£–ª—å—è–Ω–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', 
                                              '–ß—É–≤–∞—à—Å–∫–∞—è –†–µ—Å–ø—É–±–ª–∏–∫–∞'],
            '–£—Ä–∞–ª—å—Å–∫–∏–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥': ['–ö—É—Ä–≥–∞–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–°–≤–µ—Ä–¥–ª–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–¢—é–º–µ–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', 
                                            '–ß–µ–ª—è–±–∏–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–•–∞–Ω—Ç—ã-–ú–∞–Ω—Å–∏–π—Å–∫–∏–π –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –æ–∫—Ä—É–≥ ‚Äî –Æ–≥—Ä–∞', 
                                            '–Ø–º–∞–ª–æ-–ù–µ–Ω–µ—Ü–∫–∏–π –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –æ–∫—Ä—É–≥'],
            '–°–∏–±–∏—Ä—Å–∫–∏–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥': ['–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ê–ª—Ç–∞–π', '–ê–ª—Ç–∞–π—Å–∫–∏–π –∫—Ä–∞–π', '–ò—Ä–∫—É—Ç—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–ö–µ–º–µ—Ä–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å',
                                            '–ö—Ä–∞—Å–Ω–æ—è—Ä—Å–∫–∏–π –∫—Ä–∞–π', '–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–û–º—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–¢–æ–º—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å',
                                            '–†–µ—Å–ø—É–±–ª–∏–∫–∞ –¢—ã–≤–∞', '–†–µ—Å–ø—É–±–ª–∏–∫–∞ –•–∞–∫–∞—Å–∏—è'],
            '–î–∞–ª—å–Ω–µ–≤–æ—Å—Ç–æ—á–Ω—ã–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥': ['–ê–º—É—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–ï–≤—Ä–µ–π—Å–∫–∞—è –∞–≤—Ç–æ–Ω–æ–º–Ω–∞—è –æ–±–ª–∞—Å—Ç—å', '–ö–∞–º—á–∞—Ç—Å–∫–∏–π –∫—Ä–∞–π',
                                                  '–ú–∞–≥–∞–¥–∞–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–ü—Ä–∏–º–æ—Ä—Å–∫–∏–π –∫—Ä–∞–π', '–†–µ—Å–ø—É–±–ª–∏–∫–∞ –°–∞—Ö–∞ (–Ø–∫—É—Ç–∏—è)',
                                                  '–°–∞—Ö–∞–ª–∏–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', '–•–∞–±–∞—Ä–æ–≤—Å–∫–∏–π –∫—Ä–∞–π', '–ß—É–∫–æ—Ç—Å–∫–∏–π –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –æ–∫—Ä—É–≥']
        }
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –æ–∫—Ä—É–≥–∞ –ø–æ —Å—É–±—ä–µ–∫—Ç—É
        self.subject_to_district = {}
        for district, subjects in self.federal_districts.items():
            for subject in subjects:
                self.subject_to_district[subject.lower()] = district

        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ä–µ–≥–∏–æ–Ω–æ–≤
        self.regions_mapping = {}
        
        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≥–æ—Ä–æ–¥–æ–≤ –∏ —Ä–µ–≥–∏–æ–Ω–æ–≤
        self.city_to_region = {}
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –ø–ª–æ—â–∞–¥–µ–π –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å–µ—Ç–µ–π –∏ —Ñ–æ—Ä–º–∞—Ç–æ–≤
        self.area_ranges = {
            '–º–∞–≥–Ω–∏—Ç': {
                '–ø—Ä': (250, 350),        # –ü—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –º–∞–≥–∞–∑–∏–Ω
                '–±—Ñ': (800, 1200),       # –ë–∏–∑–Ω–µ—Å-—Ñ–æ—Ä–º–∞—Ç
                '–º–¥': (300, 500),        # –ú–∞–≥–∞–∑–∏–Ω —É –¥–æ–º–∞
                '–º–∫': (200, 300),        # –ú–∞–≥–Ω–∏—Ç –ö–æ—Å–º–µ—Ç–∏–∫
                'default': (250, 350)
            },
            '–∞—à–∞–Ω': {
                '–∞—à–∞–Ω': (8000, 12000),    # –ì–∏–ø–µ—Ä–º–∞—Ä–∫–µ—Ç
                '–∞—à–∞–Ω —Å–∏—Ç–∏': (800, 1200), # –°—É–ø–µ—Ä–º–∞—Ä–∫–µ—Ç
                '–¥–∞—Ä–∫ —Å—Ç–æ—Ä': (500, 1500), # –¢–µ–º–Ω—ã–π —Å–∫–ª–∞–¥
                '–Ω–∞—à–∞ —Ä–∞–¥—É–≥–∞': (800, 2500), # –°—É–ø–µ—Ä–º–∞—Ä–∫–µ—Ç
                'default': (1000, 2000)
            },
            '–ø—è—Ç–µ—Ä–æ—á–∫–∞': {
                'default': (300, 450)
            },
            '–ø—è—Ç—ë—Ä–æ—á–∫–∞': {
                'default': (300, 450)
            },
            '–ø–µ—Ä–µ–∫—Ä–µ—Å—Ç–æ–∫': {
                'default': (750, 1200)
            },
            '–ø–µ—Ä–µ–∫—Ä—ë—Å—Ç–æ–∫': {
                'default': (750, 1200)
            },
            '–¥–∏–∫—Å–∏': {
                '–¥–∏–∫—Å–∏': (300, 500),
                'default': (300, 500)
            },
            '–æ–∫–µ–π': {
                'default': (5000, 10000)
            },
            'x5 united': {
                'default': (750, 1200)
            },
            '–ø—è—Ç—ä–Ω–∏—Ü–∞': {
                'default': (250, 350)
            },
            '—á–∏–∂–∏–∫': {
                'default': (250, 350)
            },
            '–ø–µ—Ä–µ–∫—Ä—ë—Å—Ç–æ–∫-–¥–∂–µ–º': {
                'default': (250, 350)
            },
            'default': {
                '–≥–∏–ø–µ—Ä–º–∞—Ä–∫–µ—Ç': (8000, 12000),
                '—Å—É–ø–µ—Ä–º–∞—Ä–∫–µ—Ç': (700, 1000),
                '–º–∞–≥–∞–∑–∏–Ω —É –¥–æ–º–∞': (200, 300),
                '—Ç–æ—Ä–≥–æ–≤—ã–π —Ü–µ–Ω—Ç—Ä': (5000, 20000),
                '—Å–∫–ª–∞–¥—Å–∫–æ–π –∫–ª—É–±': (3000, 5000),
                'default': (200, 400)
            }
        }

        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è store_type –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ—Ç–∏ –∏ —Ñ–æ—Ä–º–∞—Ç–∞
        self.store_type_mapping = {
            '–º–∞–≥–Ω–∏—Ç': {
                '–ø—Ä': '–º–∞–≥–∞–∑–∏–Ω —É –¥–æ–º–∞'.capitalize(),
                '–±—Ñ': '—Å—É–ø–µ—Ä–º–∞—Ä–∫–µ—Ç'.capitalize(),
                '–º–¥': '–º–∞–≥–∞–∑–∏–Ω —É –¥–æ–º–∞'.capitalize(),
                '–º–∫': '–∫–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–∏–π'.capitalize(),
                'default': '–º–∞–≥–∞–∑–∏–Ω —É –¥–æ–º–∞'.capitalize()    
            },
            '–∞—à–∞–Ω': {
                '–∞—à–∞–Ω': '–≥–∏–ø–µ—Ä–º–∞—Ä–∫–µ—Ç'.capitalize(),
                '–∞—à–∞–Ω —Å–∏—Ç–∏': '—Å—É–ø–µ—Ä–º–∞—Ä–∫–µ—Ç'.capitalize(),
                '–¥–∞—Ä–∫ —Å—Ç–æ—Ä': '—Ç—ë–º–Ω—ã–π —Å–∫–ª–∞–¥'.capitalize(),
                '–Ω–∞—à–∞ —Ä–∞–¥—É–≥–∞': '—Å—É–ø–µ—Ä–º–∞—Ä–∫–µ—Ç'.capitalize(),
                'default': '–≥–∏–ø–µ—Ä–º–∞—Ä–∫–µ—Ç'.capitalize()
            },
            '–ø—è—Ç–µ—Ä–æ—á–∫–∞': {'default': '–º–∞–≥–∞–∑–∏–Ω —É –¥–æ–º–∞'.capitalize()},
            '–ø—è—Ç—ë—Ä–æ—á–∫–∞': {'default': '–º–∞–≥–∞–∑–∏–Ω —É –¥–æ–º–∞'.capitalize()},
            '–ø–µ—Ä–µ–∫—Ä–µ—Å—Ç–æ–∫': {'default': '—Å—É–ø–µ—Ä–º–∞—Ä–∫–µ—Ç'.capitalize()},
            '–ø–µ—Ä–µ–∫—Ä—ë—Å—Ç–æ–∫': {'default': '—Å—É–ø–µ—Ä–º–∞—Ä–∫–µ—Ç'.capitalize()},
            '–¥–∏–∫—Å–∏': {'–¥–∏–∫—Å–∏': '–º–∞–≥–∞–∑–∏–Ω —É –¥–æ–º–∞'.capitalize(), 'default': '–º–∞–≥–∞–∑–∏–Ω —É –¥–æ–º–∞'.capitalize()},
            '–æ–∫–µ–π': {'default': '–≥–∏–ø–µ—Ä–º–∞—Ä–∫–µ—Ç'.capitalize()},
            'x5 united': {'default': '–º–∞–≥–∞–∑–∏–Ω —É –¥–æ–º–∞'.capitalize()},
            '–ø—è—Ç—ä–Ω–∏—Ü–∞': {'default': '–º–∞–≥–∞–∑–∏–Ω —É –¥–æ–º–∞'.capitalize()},
            '—á–∏–∂–∏–∫': {'default': '–¥–∏—Å–∫–∞—É–Ω—Ç–µ—Ä'.capitalize()},
            '–ø–µ—Ä–µ–∫—Ä—ë—Å—Ç–æ–∫-–¥–∂–µ–º': {'default': '–º–∞–≥–∞–∑–∏–Ω —É –¥–æ–º–∞'.capitalize()},
            'default': {
                '–≥–∏–ø–µ—Ä–º–∞—Ä–∫–µ—Ç': '–≥–∏–ø–µ—Ä–º–∞—Ä–∫–µ—Ç'.capitalize(),
                '—Å—É–ø–µ—Ä–º–∞—Ä–∫–µ—Ç': '—Å—É–ø–µ—Ä–º–∞—Ä–∫–µ—Ç'.capitalize(),
                '–º–∞–≥–∞–∑–∏–Ω —É –¥–æ–º–∞': '–º–∞–≥–∞–∑–∏–Ω —É –¥–æ–º–∞'.capitalize(),
                '—Ç–æ—Ä–≥–æ–≤—ã–π —Ü–µ–Ω—Ç—Ä': '—Ç–æ—Ä–≥–æ–≤—ã–π —Ü–µ–Ω—Ç—Ä'.capitalize(),
                '—Å–∫–ª–∞–¥—Å–∫–æ–π –∫–ª—É–±': '—Å–∫–ª–∞–¥—Å–∫–æ–π'.capitalize(),
                'default': '–º–∞–≥–∞–∑–∏–Ω —É –¥–æ–º–∞'.capitalize()
            }
        }

    def get_current_api_key(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ API –∫–ª—é—á–∞"""
        if not self.api_keys:
            return None
        return self.api_keys[self.current_key_index]

    def switch_to_next_key(self):
        """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π API –∫–ª—é—á"""
        if not self.api_keys:
            return False
        
        original_index = self.current_key_index
        self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)
        
        if self.current_key_index == original_index:
            logger.error("–í—Å–µ –∫–ª—é—á–∏ –ø–µ—Ä–µ–±—Ä–∞–Ω—ã, –ª–∏–º–∏—Ç –∏—Å—á–µ—Ä–ø–∞–Ω!")
            return False
            
        logger.info(f"–ü–µ—Ä–µ–∫–ª—é—á–∏–ª–∏—Å—å –Ω–∞ –∫–ª—é—á: {self.api_keys[self.current_key_index][:8]}...")
        return True

    def get_sales_data(self, retail_chain: str, address: str, sale_date: date) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –¥–∞—Ç—É"""
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –°–¢–†–û–ö–ê - —É–±—Ä–∞–ª –ª–∏—à–Ω–∏–µ —Å–∫–æ–±–∫–∏ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ —Ç–∞–±–ª–∏—Ü—ã
            sql = """
            SELECT 
                SUM(sales_quantity) as total_quantity,
                SUM(sales_amount_rub) as total_amount,
                AVG(avg_sell_price) as avg_sell,
                AVG(avg_cost_price) as avg_cost
            FROM [Stage].[bi].[ALL_DATA_COMPETITORS_CHIPS]
            WHERE retail_chain = ? AND address = ? AND sale_date = ?
            GROUP BY retail_chain, address, sale_date
            """
            cursor.execute(sql, retail_chain, address, sale_date)
            row = cursor.fetchone()
            
            if row:
                return {
                    'sales_quantity': row.total_quantity or 0,
                    'sales_amount_rub': row.total_amount or 0.0,
                    'avg_sell_price': row.avg_sell or 0.0,
                    'avg_cost_price': row.avg_cost or 0.0
                }
            else:
                return {'sales_quantity': 0, 'sales_amount_rub': 0.0, 'avg_sell_price': 0.0, 'avg_cost_price': 0.0}
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö: {e}")
            return {'sales_quantity': 0, 'sales_amount_rub': 0.0, 'avg_sell_price': 0.0, 'avg_cost_price': 0.0}

    def get_data_from_source_table(self) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π —Å sale_date - –¢–û–õ–¨–ö–û —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏"""
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            
            # –ò—â–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–∏ —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ STORE_CHARACTERISTICS
            sql = """
            SELECT DISTINCT 
                adc.sale_date, 
                adc.retail_chain, 
                adc.store_format, 
                adc.address
            FROM [Stage].[bi].[ALL_DATA_COMPETITORS_CHIPS] adc
            LEFT JOIN [Stage].[bi].[STORE_CHARACTERISTICS] sc 
                ON sc.retail_chain = adc.retail_chain 
                AND sc.address = adc.address
                AND sc.sale_date = adc.sale_date
            WHERE adc.retail_chain IS NOT NULL 
                AND adc.address IS NOT NULL
                AND adc.sales_quantity > 0
                AND adc.sales_amount_rub > 0
                AND sc.retail_chain IS NULL
            OPTION (MAXDOP 1)
            """
            cursor.execute(sql)
            rows = cursor.fetchall()
            
            result = []
            for row in rows:
                result.append({
                    'sale_date': row.sale_date, 
                    'retail_chain': row.retail_chain,
                    'store_format': row.store_format, 
                    'address': row.address
                })
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(result)} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏")
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–∞–±–ª–∏—Ü—ã: {e}")
            return []

    def update_existing_stores_sales(self) -> int:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å—è—Ö STORE_CHARACTERISTICS"""
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            
            sql = """
            UPDATE sc
            SET 
                sales_quantity = sales_data.total_quantity,
                sales_amount_rub = sales_data.total_amount,
                avg_sell_price = sales_data.avg_sell,
                avg_cost_price = sales_data.avg_cost,
                created_at = GETDATE()
            FROM [Stage].[bi].[STORE_CHARACTERISTICS] sc
            INNER JOIN (
                SELECT 
                    retail_chain,
                    address,
                    sale_date,
                    SUM(sales_quantity) as total_quantity,
                    SUM(sales_amount_rub) as total_amount,
                    AVG(avg_sell_price) as avg_sell,
                    AVG(avg_cost_price) as avg_cost
                FROM [Stage].[bi].[ALL_DATA_COMPETITORS_CHIPS]
                WHERE sales_quantity > 0 AND sales_amount_rub > 0
                GROUP BY retail_chain, address, sale_date
            ) sales_data ON sc.retail_chain = sales_data.retail_chain 
                AND sc.address = sales_data.address
                AND sc.sale_date = sales_data.sale_date
            WHERE sc.sales_quantity = 0  -- –æ–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —É –∫–æ–≥–æ –ø—Ä–æ–¥–∞–∂–∏ = 0
            """
            
            cursor.execute(sql)
            updated_count = cursor.rowcount
            conn.commit()
            
            logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏: {updated_count}")
            return updated_count
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –ø—Ä–æ–¥–∞–∂: {e}")
            return 0

    def get_store_type(self, network: str, format_type: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –º–∞–≥–∞–∑–∏–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ—Ç–∏ –∏ —Ñ–æ—Ä–º–∞—Ç–∞"""
        network_lower = network.lower()
        format_lower = format_type.lower() if format_type else 'default'
        
        if network_lower in self.store_type_mapping:
            network_types = self.store_type_mapping[network_lower]
            if format_lower in network_types:
                return network_types[format_lower]
            return network_types.get('default', '–ú–∞–≥–∞–∑–∏–Ω —É –¥–æ–º–∞')
        
        return self.store_type_mapping['default'].get(format_lower, 
                    self.store_type_mapping['default']['default'])

    def get_area_from_range(self, network: str, format_type: str) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–ª–æ—â–∞–¥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–ª—è —Å–µ—Ç–∏ –∏ —Ñ–æ—Ä–º–∞—Ç–∞"""
        network_lower = network.lower()
        format_lower = format_type.lower() if format_type else 'default'
        
        if network_lower in self.area_ranges:
            network_ranges = self.area_ranges[network_lower]
            if format_lower in network_ranges:
                area_range = network_ranges[format_lower]
            else:
                area_range = network_ranges.get('default', (200, 400))
        else:
            default_ranges = self.area_ranges['default']
            if format_lower in default_ranges:
                area_range = default_ranges[format_lower]
            else:
                area_range = default_ranges['default']
        
        return int(np.random.uniform(area_range[0], area_range[1]))

    def save_to_database(self, data: Dict[str, Any]) -> bool:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ—Ä–≥–æ–≤–æ–π —Ç–æ—á–∫–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        retail_chain = data.get('retail_chain', '')
        store_format = data.get('store_format', '')
        address = data.get('address', '')
        sale_date = data.get('sale_date') or date.today()

        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏
            check_sql = """
            SELECT COUNT(*) FROM [Stage].[bi].[STORE_CHARACTERISTICS] 
            WHERE retail_chain = ? AND address = ? AND sale_date = ?
            """
            cursor.execute(check_sql, retail_chain, address, sale_date)
            count = cursor.fetchone()[0]
            
            if count > 0:
                logger.info(f"–ó–∞–ø–∏—Å—å —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {retail_chain} - {address} - {sale_date}")
                return False

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö
            sales_data = self.get_sales_data(retail_chain, address, sale_date)
            
            # –ü–æ–ª—É—á–∞–µ–º –≥–µ–æ–¥–∞–Ω–Ω—ã–µ
            geodata = self.get_location_info(address)
            
            if geodata and geodata.get('success'):
                city = geodata.get('city', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                federal_district = geodata.get('federal_district', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                federal_subject = geodata.get('federal_subject', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                lat = geodata.get('lat', 0)
                lon = geodata.get('lon', 0)
            else:
                # –†–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∞–¥—Ä–µ—Å–∞
                extracted = self._extract_from_address(address)
                city = extracted['city']
                federal_district = extracted['region']
                federal_subject = extracted['federal_subject']
                lat = 0
                lon = 0

            area_m2 = self.get_area_from_range(retail_chain, store_format)
            has_alcohol_department = 1  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –µ—Å—Ç—å
            has_snacks = 1  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –µ—Å—Ç—å
            store_type = self.get_store_type(retail_chain, store_format)
            address_hash = generate_address_hash(address)

            sql = """
            INSERT INTO [Stage].[bi].[STORE_CHARACTERISTICS] 
            (retail_chain, store_format, store_type, address, sale_date, city, 
            federal_district, federal_subject,
            sales_quantity, sales_amount_rub, avg_sell_price, avg_cost_price, 
            lat, lon, area_m2, has_alcohol_department, has_snacks, created_at, address_hash)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, GETDATE(), ?)
            """
            
            cursor.execute(sql, 
                        retail_chain, store_format, store_type, address, sale_date,
                        city, federal_district, federal_subject,
                        sales_data['sales_quantity'], sales_data['sales_amount_rub'],
                        sales_data['avg_sell_price'], sales_data['avg_cost_price'],
                        lat, lon, area_m2, has_alcohol_department, has_snacks, address_hash)
            conn.commit()
            
            logger.info(f"–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {retail_chain} - {address} - {sale_date}")
            return True
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {retail_chain} - {address}: {e}")
            return False

    def get_location_info(self, address: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–∏ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–æ –†–æ—Å—Å–∏–∏"""
        if not self.api_keys:
            logger.warning("API –∫–ª—é—á–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã. –ì–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ.")
            return None
            
        max_retries = len(self.api_keys) * 2  # –î–≤–æ–π–Ω–æ–π –∑–∞–ø–∞—Å –ø–æ–ø—ã—Ç–æ–∫
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                address_with_country = f"{address}, –†–æ—Å—Å–∏—è"
                encoded_address = urllib.parse.quote(address_with_country)
                
                params = {
                    'geocode': address_with_country,
                    'format': 'json',
                    'results': 5,
                    'apikey': self.get_current_api_key(),
                    'lang': 'ru_RU'
                }
                
                logger.info(f"–ì–µ–æ–∫–æ–¥–∏—Ä—É–µ–º –∞–¥—Ä–µ—Å: {address}")
                
                response = self.session.get(self.geocoder_url, params=params, timeout=15)
                
                if response.status_code != 200:
                    logger.error(f"–û—à–∏–±–∫–∞ HTTP {response.status_code}")
                    
                    if response.status_code == 403 or "limit" in response.text.lower():
                        logger.warning("–õ–∏–º–∏—Ç API –∏—Å—á–µ—Ä–ø–∞–Ω –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫–ª—é—á–∞")
                        if not self.switch_to_next_key():
                            return {"success": False, "api_limit_exceeded": True}
                        retry_count += 1
                        time.sleep(1)
                        continue
                    
                    return None
                    
                response.raise_for_status()
                geocode_data = response.json()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç –≤ JSON –æ—Ç–≤–µ—Ç–µ
                if (geocode_data.get('status') == 403 or 
                    'limit' in str(geocode_data).lower()):
                    logger.warning("–õ–∏–º–∏—Ç API –∏—Å—á–µ—Ä–ø–∞–Ω –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫–ª—é—á–∞")
                    if not self.switch_to_next_key():
                        return {"success": False, "api_limit_exceeded": True}
                    retry_count += 1
                    time.sleep(1)
                    continue
                
                location_info = self._parse_geocode(geocode_data, address)
                
                if location_info:
                    logger.info(f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {address}")
                    return location_info
                else:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∞–¥—Ä–µ—Å: {address}")
                    return None
                    
            except requests.exceptions.RequestException as e:
                logger.error(f"–°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è –∞–¥—Ä–µ—Å–∞ {address}: {e}")
                retry_count += 1
                time.sleep(2)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞–¥—Ä–µ—Å–∞ {address}: {e}")
                return None
        
        logger.error(f"–ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –∞–¥—Ä–µ—Å–∞: {address}")
        return None

    def _parse_geocode(self, data: Dict, original_address: str) -> Optional[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –≥–µ–æ–∫–æ–¥–µ—Ä–∞"""
        try:
            if not data or 'response' not in data:
                return None
                
            response = data['response']
            collection = response.get('GeoObjectCollection', {})
            
            if 'metaDataProperty' in collection:
                meta = collection['metaDataProperty']['GeocoderResponseMetaData']
                found = meta.get('found', 0)
                if found == 0:
                    return None
            
            features = collection.get('featureMember', [])
            
            if not features:
                return None
            
            for feature in features:
                geo_object = feature.get('GeoObject', {})
                
                if not geo_object:
                    continue
                
                meta_data = geo_object.get('metaDataProperty', {}).get('GeocoderMetaData', {})
                address_details = meta_data.get('Address', {})
                address_components = address_details.get('Components', [])
                
                is_russian = False
                federal_district = None
                federal_subject = None
                city = None
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä–∞–Ω—É
                for component in address_components:
                    kind = component.get('kind', '')
                    name = component.get('name', '')
                    
                    if kind == 'country' and name == '–†–æ—Å—Å–∏—è':
                        is_russian = True
                        break
                
                if not is_russian:
                    continue
                    
                # –ò—â–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
                for component in address_components:
                    kind = component.get('kind', '')
                    name = component.get('name', '')
                    
                    if kind == 'locality':
                        city = name
                    elif kind == 'province':
                        federal_subject = name
                    elif kind == 'area' and not federal_subject:
                        federal_subject = name
                    elif kind == 'region':
                        if '—Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥' in name.lower():
                            federal_district = name
                        elif not federal_subject:
                            federal_subject = name
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥ –ø–æ —Å—É–±—ä–µ–∫—Ç—É
                if not federal_district and federal_subject:
                    federal_district = self._find_federal_district(federal_subject)
                
                # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                point = geo_object.get('Point', {})
                pos = point.get('pos')
                if not pos:
                    continue
                    
                lon, lat = map(float, pos.split())
                
                return {
                    'lat': lat,
                    'lon': lon,
                    'city': city or '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ',
                    'federal_district': federal_district or '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ',
                    'federal_subject': federal_subject or '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ',
                    'success': True
                }
            
            return None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≥–µ–æ–∫–æ–¥–µ—Ä–∞: {e}")
            return None
    
    def _find_federal_district(self, subject: str) -> str:
        """–ü–æ–∏—Å–∫ —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–≥–∞ –ø–æ —Å—É–±—ä–µ–∫—Ç—É –†–§"""
        subject_lower = subject.lower()
        for subject_name, district in self.subject_to_district.items():
            if subject_name in subject_lower:
                return district
        return '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
    
    def _extract_from_address(self, address: str) -> Dict:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ –∏ —Ä–µ–≥–∏–æ–Ω–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∞–¥—Ä–µ—Å–∞"""
        address_lower = address.lower()
        
        region = '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
        federal_subject = '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
        city = '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
        
        # –ò—â–µ–º —Å—É–±—ä–µ–∫—Ç –†–§ –≤ –∞–¥—Ä–µ—Å–µ
        all_subjects = []
        for subjects in self.federal_districts.values():
            all_subjects.extend(subjects)
        
        for subject in all_subjects:
            if subject.lower() in address_lower:
                federal_subject = subject
                region = self._find_federal_district(subject)
                break
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–æ—Ä–æ–¥–∞
        patterns = [
            r'(?:–≥\.|–≥–æ—Ä–æ–¥|–≥–æ—Ä\.)\s*([^,]+)',
            r',\s*([^,]+?)\s*(?:–≥|–≥–æ—Ä–æ–¥|\(–≥\))',
            r'^([^,]+?),',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, address, re.IGNORECASE)
            if match:
                potential_city = match.group(1).strip()
                if not any(word in potential_city.lower() for word in 
                        ['—É–ª', '—É–ª–∏—Ü–∞', '–ø—Ä–æ—Å–ø–µ–∫—Ç', '–ø—Ä', '–ø–ª–æ—â–∞–¥—å', '–ø–µ—Ä', '–ø–µ—Ä–µ—É–ª–æ–∫']):
                    city = potential_city
                    break
        
        return {
            'city': city, 
            'region': region,
            'federal_subject': federal_subject
        }

    def process_source_table(self, max_requests: int = 2000, sleep_between: float = 0.5) -> Dict[str, int]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –∞–¥—Ä–µ—Å–∞ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –¥–∞—Ç–æ–π –ø—Ä–æ–¥–∞–∂–∏"""
        stats = {
            'fetched': 0, 
            'processed': 0, 
            'saved': 0, 
            'errors': 0,
            'api_requests': 0, 
            'api_limit_hit': False
        }

        try:
            rows = self.get_data_from_source_table()
            stats['fetched'] = len(rows)
            rows_to_process = rows[:max_requests]
            total_to_process = len(rows_to_process)
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏: {stats['fetched']}")
            logger.info(f"–ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ (–ª–∏–º–∏—Ç {max_requests}): {total_to_process}")
            
            if total_to_process == 0:
                return stats

            pbar = tqdm(total=total_to_process, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–¥—Ä–µ—Å–æ–≤", unit="–∞–¥—Ä–µ—Å")
            
            for row in rows_to_process:
                if stats['api_limit_hit']:
                    break

                try:
                    sale_date = row['sale_date']
                    retail_chain = row['retail_chain']
                    store_format = row.get('store_format', '')
                    address = row['address']
                    
                    stats['processed'] += 1

                    pbar.set_postfix({
                        '–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ': stats['processed'],
                        '–æ—Å—Ç–∞–ª–æ—Å—å': total_to_process - stats['processed'],
                        '—Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ': stats['saved'],
                        '–æ—à–∏–±–∫–∏': stats['errors'],
                        'api_–∑–∞–ø—Ä–æ—Å–æ–≤': stats['api_requests']
                    })
                    pbar.update(1)

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
                    data = {
                        'sale_date': sale_date,
                        'retail_chain': retail_chain,
                        'store_format': store_format,
                        'address': address
                    }
                    
                    saved = self.save_to_database(data)
                    if saved:
                        stats['saved'] += 1
                    else:
                        stats['errors'] += 1

                    stats['api_requests'] += 1
                    time.sleep(sleep_between)

                except Exception as e_row:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–æ–∫–∏ {row}: {e_row}")
                    stats['errors'] += 1

            pbar.close()
            logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. API –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['api_requests']}")
            return stats

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –∏—Å—Ö–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã: {e}")
            stats['errors'] += 1
            return stats
        

def main():
    print("üîç –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î")
    
    # –°–ø–∏—Å–æ–∫ API –∫–ª—é—á–µ–π
    API_KEYS = [
        '4eafaf6f-51c9-47d0-be01-cddf8e94f4a7',
        '18ffa901-3ca3-4490-9222-ed66046d64d7',
        '27b61e45-ccdd-4c16-b6c7-e9c6e38c01f7',
        '694470aa-33bb-49c8-a0ba-1be0e99ec787',
        '54bf3eb1-a2d7-400b-9928-acc90a2a5780',
        '22706d49-4f15-41d6-892b-cde7473200de',
        '2056b23c-648c-4952-ac7a-d5952575e7db',
        '4f0efc9d-e486-4952-983d-dd4847d599a8',
        '413dcd39-ba92-43a2-92e1-51cec7aa26cd',
        '57bbd123-1ee5-48e8-95d3-9207318b7450',
        'c81804b3-3b27-400e-8c8e-3c2d688d9d43',
        '08fc2bb0-4759-40ff-b507-48005ba26947',
        '7b730765-17f9-4eec-822b-839c92ad7cad'
    ]
    
    processor = YandexGeoProcessor(api_keys=API_KEYS)

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª—é—á–∞—Ö
    print(f"üîë –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {len(API_KEYS)} –∫–ª—é—á–µ–π")
    
    # 1. –°–Ω–∞—á–∞–ª–∞ –æ–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∑–∞–ø–∏—Å–∏ —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏
    print("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–∞–≥–∞–∑–∏–Ω–∞—Ö...")
    updated_count = processor.update_existing_stores_sales()
    print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏: {updated_count}")
    
    # 2. –ó–∞—Ç–µ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–æ–≤—ã–µ –º–∞–≥–∞–∑–∏–Ω—ã
    print("üîç –ü–æ–∏—Å–∫ –Ω–æ–≤—ã—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤ —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏...")
    rows_to_process = processor.get_data_from_source_table()
    total_records = len(rows_to_process)
    print(f"üìã –í—Å–µ–≥–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_records}")
    
    if total_records > 0:
        stats = processor.process_source_table(
            max_requests=40000,
            sleep_between=0.1
        )
        
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
        print(f"   –í—Å–µ–≥–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π: {stats['fetched']}")
        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['processed']}")
        print(f"   API –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['api_requests']}")
        print(f"   –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {stats['saved']}")
        print(f"   –û—à–∏–±–æ–∫: {stats['errors']}")
        
        remaining = total_records - stats['processed']
        print(f"   –û—Å—Ç–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å: {remaining}")
        
        if stats['api_limit_hit']:
            print("\n‚ö†Ô∏è  –í—Å–µ –∫–ª—é—á–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã! –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞.")
        elif stats['api_requests'] >= 40000:
            print("\n‚ö†Ô∏è  –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –≤ 40000 API –∑–∞–ø—Ä–æ—Å–æ–≤. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∑–∞–≤—Ç—Ä–∞ –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è.")
    else:
        print("‚úÖ –ù–æ–≤—ã—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ—Ç")

if __name__ == "__main__":
    main()